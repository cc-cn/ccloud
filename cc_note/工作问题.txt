

caffe/examples/ssd_detect.ipynb给出了在jupyter上测试图片的脚本！！研究一下

设计一种网络，在训练的时候网络容量比较大，测试的时候，则比较小。

好好研究一下 ~/caffe/build/tools/caffe，为何测试的gpu是第一张训练的gpu？？怎么改？

读通卷积层源码，不懂的地方问胡。？？整取自己会写一个简单的层！！hello，world！！

如何利用多分类模型pretrain其中的子类？这与直接过滤出子类相比有优势吗？
/有想法，做实验！！

liuhao：实验一下有没有预训练模型的结果的影响多大？基础网络vgg系列已经不流行了，多关注一下目前比较好的基础网络。darknet？
//不同初始化方式都会带来很大的影响，何况是有没有pretrain model。类别丰富，数据量巨大的ImageNet无疑是用来训练pretrain model的绝好数据。


从python接口输出feature：caffe官网有示例：http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb
从c++接口输出feature

layers转化成python代码在哪里？怎么才能根据cpp文件知道python调用接口？好好研究caffe.proto





eltwise--shortcut加还是减法？//家丞：加法，按理也应该是加法好

hu的代码可以合成lmdb，看看！

实现一个分类算法，会换网络。

因为训练图片尺寸不一，resize会带来形状变化，能否训练时不resize，测试时resize？//与算法有关，rfcn不需要resize，空间金字塔。
复现py-RFCN，并改造成方便使用的形式。然后训练人车检测模型。理解原理

完全使用pascal数据格式？先想想两者优劣再问问灏哥做法。//深入源码之后这个问题就迎刃而解了，还是用pascal数据结构好。因为很多开源框架都是用这个数据结构。熟悉一次就一本万利。

任取一个正整数，有多大概率是能写成两个整数平方和？猜测0，证？
任意一个矩阵，向里面任意填整数，那么行列式是奇数的可能性大，还是偶数的可能性大？

100维单位球面上均匀分布100w个点，求最小夹角。//？50~60度

今天copy了一个300G的文件，很慢，估计要一天。。。越到后面越慢，不知何故。查看一下cpu占用，只用了单核3%.
写一个多核copy的脚本！！
//尝试写了一个多核copy的脚本，没有带来效果，Google了一下发现瓶颈不是cpu or 内存，而是硬盘读写速度！！ssd对小文件读写会提高很多。。

min_size !!!!==== person_height

实验了我的根据像素变化的tracking，效果不好。
优点：1、代码量极小，凡是动的物体，即使很小也可以测出来。
缺点：1、慢；2、停下来的人无法跟踪；3、影子也会被测出来；4、一旦断掉就找不到了。

cpp版本的测试函数不太好改batch_size,我再尝试尝试／／ｄｅｐｌｏｙ里可以改
ssd多卡训练的机制，三张卡训练的话怎么分配batch_size／／一般来说是均分的，不同ｇｒｏｕｐ可能有数据交换。
问题：为什么4张卡占得显存不一样，第一张是另外三张的两倍。
问题：为什么model只有1M，而占用显存却比之前400x600――Tinyvgg 20M model占用的显存还大？／／关键开网络计算方式
追踪一下overlap_threshhold参数的作用
shell脚本从键盘读取数据：read -r -p "Are You Sure? [Y/n] " input //从键盘输入，并将输入存入变量$input
安装软件遇到输入用y/n?的时候，10s没有输入则自动y //网上查了一下，可以使用spawn expect交互式命令，但缺点是需要先安装expect，比较麻烦。详见http://blog.csdn.net/donglynn/article/details/51536212； http://www.cnblogs.com/lixigang/articles/4849527.html
ssd中，loss和mbox_loss分别是怎么算的？//mbox_loss是ssd的最终输出loss，根据solver.cpp里的代码，loss表示一种平均的，光滑化的loss。用mbox_loss更好
model-libs改名字。。why？//涉及到pretrain，同名layer会被初始化  
在两处安装了opencv，why？一个是系统环境下的，可删？？ 一个是自定义环境下的。尝试在113服务器上搭建环境，没有单独安装opencv，只在anaconda里安装了，最后也可以正常使用！！需要注意的是要改一下.bashrc文件里涉及到opencv包的路径！！具体见113 .bashrc文件。
几种权重初始化方式？xavier和msra类似，适用于relu激活函数是。好处是可以让每一层的输出数据方差不变。信息更均匀。
重写parse_log脚本

如果再加一个输出层，那之前16w预训练model还能用吗？那些是超参，哪些是网络结构？不能

深入理解prototxt作用，caffe网络运算机制。
test.prototxt中detection_eval层参数overlap_threshold的含义？  这是一个很关键的参数，在计算evalution的时候，如果预测box和groundtruth重叠部分大于overlap_threshold，且类别相同，则认为是预测对了。通常设置为0.5

deploy最后那两个参数是什么意思？？改成0.3后还是有一点点影响性能的！！top_k是nms留下的box数量。keep_top_k是根据confidence_threshold最终留下的box数量。这个数量就是最多检测出的框的数量。可视化的时候有时候还会加nms和confidence_threshold，作用分别是在前面检测出的keep_top_k的基础上，对不同类别做nms以及对可视化的设置confidence_threshold。 
 参见源码src/caffe/layers/detection_output_layer.cpp


# If you would like to test a model you trained, you can do:
#  python examples/ssd/score_ssd_pascal.py

shell复制粘贴多出～0   1～的问题！！自带终端没有这个问题，学用tmux吧
为什么会在训练过程中出现out of memory????猜测test这一步占用额外显存
不用pretrain从头试试？？？直接令pretrain_model = "" 即可
如何写makefile文件？
从win10启动ubuntu，从ubuntu启动win10。gpt格式
在python里可以调用cpp编译的可执行文件。详见caffe-root/scripts/create_annoset.py
更改一下生成lmdb的方式，现有的太乱了。且不适合只生成test.lmdb
如何直接从内存实现c++，python变量互相调用？
写一个能对比两个可视化结果的脚本，以后会经常用到！
python 新建文件夹
gt分布直方图（scale，ratio）

标准ssd里开头用的是VGG16, 那如何自定义小网络呢？？？好好看看胡扬阳生成网络的那个函数！！
 一个epoch中，batchsize不会重复选择吗？源码！
为什么--gpu ，--snapshot后面，有的用等于号，有的用空格?还是源码！！
aspect ratio的含义，在官网ssd中是指宽高比（ http://blog.csdn.net/u010167269/a  rticle/details/52563573），而胡扬阳的含义是高宽，找到源码看看！
找到weight_decay接口源码？
config文件中SCALE: 320含义？  追踪到lib/roi_data_layer/minibatch.py，

设定ppt长宽比。
keynote：右侧选择 文稿-幻灯片大小-自定
powerpoint：

哪些输出被重定向了？
./run.sh > log1
./run.sh > log2 &
nohup ./run.sh > log3  2>&1 &
前两个效果一样，log里只有主函数的输出。第三个还有网络的读取等记录。这与标准输出和标准错误输出有关。

mac自带图片查看命令： open ./*    就可以查看当前文件夹下所有图片。
make编译的前后变化？作用？主要是将一些cpp文件转化为可执行文件。其实自己编写执行一个cpp文件可是分两步，先编译产生可执行文件，在执行可执行文件。
添加python环境变量是啥意思？.bashrc里可设定当前用户的环境变量。在里面可添加PYTHONPATH，这样在import时就从这些路径搜索。进入python命令行，print(os.sys.path)可查看python环境变量。

今天胡扬阳也在预处理？跑caffe网络也要cpu
能否用gpu来做视频转码？要写cuda脚本
teamviewer为什么卡？公司电脑显卡原因？公司网速慢
blob数据怎么读写？faster_rcnn.test里有_get_blobs函数。本质上是一个dic
vis_detection函数看熟了！
make？
生成一个随机矩阵，看看图像是什么样子？
py-faster-rcnn没有用到roi_pooling_layer.cu和 roi_pooling_layer.cpp文件？？用end2end成功迭代200次。
涉及到分割，标注集中有分割的信息？/yes
14*14*256―――>28*28*256是怎么用卷积网络做到的？用decov
仿照roi_pooling写一个roi_align，这个完成了后在做libraf中夜间的人脸和上半身检测。
具体资料如下： caffe/src/caffe/layers/roi_pooling.cpp
你先看一下这个代码（争取读懂），然后读一下下面的这个paper：
maskrcnn（网上搜论文），里面有roialign的具体内容， 有什么不懂的找我讨论啊
tensorflow版的maskrcnn中，libs/boxes/roi.py文件下有roi_align函数名，但具体内容。

晶晶：比如 你以后要是需要修改一些参数 anchor的大小 nms参数 等等你现在知道在哪里 怎么设置 原理是什么 要用的时候就快了呀
test.py tarin.py test_net.py train_net.py pascal_voc.py可以从这里开始
找到两种网络超参数设定的地方以及接口。。
 


安装faster-rcnn官方指南，解压三个数据文件的顺序不能变，否则产生的文件也不同。！！！

运行./tools/demo.py时提示错误，怀疑是caffemodel的数据有问题，把demo.py109行默认的vgg16换成zf之后可以测试成功。已验证确实是数据的问题。。。

安装官方py-faster-rcnn再次失败，第四步 make -j8 && make pycaffe有error。／cudnn版本过旧，可百度到错误原因。
 
将输出写入到log文档，从log文档读取iter，loss。并作出图像。
train.py里import  caffe文件在哪儿？胡扬阳说这是由cpp文件生成的，直接看sgd_solver.cpp
找到每个超参数接口/frcnn/lib/tools/train_net.py
max_iter没有按照设置的运行？执行文件里设置了
solving…错误原因：h5文件key是person_upper,而不是face。。。大坑！
 
frcnn训练数据和网络model？测试数据？~/data/img_label, ~/frcnn/jobs/pd/task1/models_solverstates这里面是训练好的参数吗？我跑的model只是测试过程？yes
那训练的执行文件在哪里？没给出，自己模仿run.sh写.
为什么会有两个地方设置了RPN参数？自己配置的参数config.yaml, 默认参数~/frcnn/lib/fast_rcnn/config.py（如果没有自己配置，则采用默认参数）
pycharm可以打开服务器上的文件吗？sshfs
阅读关键函数/Desktop/R-CNN/py-faster-rcnn/lib/fast_rcnn/test/test_net
INSTANTIATE_CLASS宏！！！
对caffe哪里有疑问可以深入源码看看，/src/caffe/layer...
源码的c++文件经常使用类、类模版。这块好好学一下

视频跟踪：比较前后像素的差别。适用于镜头不动。
文件夹中如何查找指定内容？grep -H -R ‘txt’
Xavier权重初始化方法，2010一篇很好的文章。是的相邻层的var尽可能相同。
test为什么不dropout？训练的时候相当于一种平均。川川
 
强化学习是什么？看周志华
矩阵运算的复合求导
tensorboad可视化深度学习layer，很好用！
caffe的layers。prototxt有python转layers代码。不需要自己写layers 文件。
 
  
test_net.py文件中import caffe，可是没有找到这个模块。why？由c语言转码过来，搜不到。

 
研究一下ftp？用台式机搭建ftp，私有云。



搭好网络之后一定要可视化一下看看有没有结构上的错误和官方prototxt比较一下，看看有没有参数漏掉。

开源的那些经典网络，如vgg，googlenet，resnet，其参数都是千锤百炼的，很难通过自己的微调提升性能。所以，在一开始的时候，最好先照搬官方代码。等用熟了，再一点一点调参，这样更容易知道哪些参数对结果造成了影响。
试着完完整整从prototxt写搭建网络的python脚本。这样就不会有参数遗漏了。用vimdiff比较生成的prototxt和之前的是否一样。


之前一直用ssd做检测，也就是调调参数。因为做的东西太单一，好多地方形成了思维定式。比如lr先设为0.001，不增之后再设0.0001。对一些细节理解理解也不深，比如bn层参数。
最近做了一些分类问题，因为看到了和以前不同的地方，对caffe框架下的神经网络有了更全面的认识。接口方面，需要solver.prototxt,train.prototxt,test.prototxt;使用模型的时候需要deploy.prototxt.
自己搭建网络其实主要就是在生成这四个文件。

今天下载了resnet50 model作为pretrain,训练deepv，期间遇到了一些bug。
首先对照了pretrain model对应的prototxt里的层名称和model_libs.py里的层名称。一致后，开始训练。出现bias_term参数不一致问题，更改model_libs.py里的参数使之一致。
接着出现out of memory,把batchsize降为1之后才可以训练。坑呐！原来resnet50这么大。换用resnet34吧

今天上午只用了两个小时就在Tinyvgg网络中加了shortcut，并且顺利运行，这在一个月前我还觉得无从下手。pretrain可以使用，但效果如何就不知道。因为我完全是模仿resnet101中shortcut部分写的，也不知道在vgg还管不管用，纯粹是瞎尝试。要想提高尝试成功的可能性，就要对网络的原理有深入的理解。就是shortcut为什么会起作用，以及它的参数的含义。

以后所以处理数据的工作都放在一个服务器上，比如202.  其它服务器只应该有生成好的lmdb或者少量测试文件。抽个时间整合一下各个服务器数据，没用的删掉。重复的、软连的、挂载的要小心。

志成：优先考虑算法本身的替身，其次才是外部算法。

做事情很难面面俱到，无论记性多好，也不会对一个月之前做过的复杂事情的细节还清清楚楚，因此做事情应该有一个原则。比如一个主题的事情尽量放在一个大文件下。涉及到影响其他项目的代码改动尤为敏感，比如将源码改成二分类，use_gloabal_stats改为true，这些改动时间久了很容易忘掉。况且不同服务器上面的同名代码是不关联的，手动同步有很耗时。最初拿到志成ｓｓｄ训练代码的时候，我没有做优化就ｃｏｐｙ了多份，后来我在一个地方做了一些优化，之后时常会在新旧代码间切换，这带来了很多麻烦。将多次出现的路径统一用一个简短的变量表示，使得接口更人性化。这样在以后改这个路径时候就不需要每个地方都改一遍了。但旧的代码任然时不时的出现，我又不愿做重复的工作，这必然就会带来代码的混乱。所以一份代码更新之后及时同步到其他代码，这是不是小的工程量，但一次性做了也不花多少时间。比如我在不同服务器上的文件，前期１９２都放在home下，后来１１３框架搭建在home下，数据放在mnt下.最新的202则是将所有东西都放在mnt下，只是为方便工作，将它们软连接到home下。应该说202的方式才是最理想的。抽半天时间把所以服务器都搞成202的模式吧。

目前来看，似乎overlap太高会导致断帧，太低会影响precision。minsize取小点则有助于小物体检测，增加acc。

需求一直在变，一起按规划好的文件变得乱七八糟。同样的工作又要重复做。所以未来总是多变，不要急着把一切定死。

liuhao的yolo2没有自行车上的人被检出人的问题，想想原因。我的anchor太多了？
平时深入想想神经网络的原理，有了想法就做实验。比较不同模型的优劣是很好的引发思考的途径。

知识最系统的获取方式必然是来自书籍，那些从别人口中获取的知识是快餐，从公众号获取的也是快餐，且不一定健康。所以集中一段时间系统的读读书还是有必要的。明年暑假找工作的时候我应该达到一种状态，熟悉现有的深度学习网络的基本方法，搭建自己的网络，会写layers的cpp脚本。这三点目前我都没有做到。在数据处理，重复劳动方法花费的时间太多了，虽然简单不用动脑筋，但对自己的发展是十分不利的。

202:/sda 是固态盘，处理数据会快很多。可以考虑先把数据copy到这里，处理完再删掉。做一件事的方法有很多，做事之前分析一下，选择一种最优方法，这样可以事半功倍。


素食！！暴饮暴食七宗罪。
节约！！想想那些贫穷的人

面试看中工程，算法，基础，数理逻辑，态度。

学学wepon 大神 github主页是怎么维护的https://github.com/wepe/MachineLearning
以后负责一个项目的时候，git肯定是要学的。当自己有了一定的知识量的时候，可以写一些开源的东西服务他人。

ubuntu系统的备份功能，简单好用！装好cuda之后可以试试

有意识地记忆一些编程语言中常见的语法，可以大大提高变成效率！比如读写文件、time函数、数学函数等等。



参考https://blog.csdn.net/wspba/article/details/75671573
开山之作：https://arxiv.org/abs/1510.00149
机器学习中的剪枝

bnn
知识蒸馏（迁移学习）：https://arxiv.org/pdf/1503.02531.pdf，损失函数来自于两部分，大模型的特征、gt
mimic: 和知识蒸馏一样，也是学习大模型的特征，不过训练数据可以没有label
SqueezeNet、MobileNet等
ResNeXt：https://arxiv.org/pdf/1611.05431.pdf，源码https://github.com/facebookresearch/ResNeXt
ShuffleNet:  https://arxiv.org/abs/1707.01083?context=cs.CV

目前深度学习模型压缩方法的研究主要可以分为以下几个方向： 
更精细模型的设计，目前的很多网络都具有模块化的设计，在深度和宽度上都很大，这也造成了参数的冗余很多，因此有很多关于模型设计的研究，如SqueezeNet、MobileNet等，使用更加细致、高效的模型设计，能够很大程度的减少模型尺寸，并且也具有不错的性能。 
模型裁剪，结构复杂的网络具有非常好的性能，其参数也存在冗余，因此对于已训练好的模型网络，可以寻找一种有效的评判手段，将不重要的connection或者filter进行裁剪来减少模型的冗余。 
核的稀疏化，在训练过程中，对权重的更新进行诱导，使其更加稀疏，对于稀疏矩阵，可以使用更加紧致的存储方式，如CSC，但是使用稀疏矩阵操作在硬件平台上运算效率不高，容易受到带宽的影响，因此加速并不明显。 
除此之外，量化、Low-rank分解、迁移学习等方法也有很多研究，并在模型压缩中起到了非常好的效果。
GEMM：通用矩阵乘法
